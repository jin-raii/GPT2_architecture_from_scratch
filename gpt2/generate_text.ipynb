{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "9b0b0fbd",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "import os "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "66284e3b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_folder  /home/jin/gpt2_from_scratch\n"
     ]
    }
   ],
   "source": [
    "parent_folder = Path(os.getcwd()).resolve().parent\n",
    "sys.path.insert(0, str(parent_folder))\n",
    "print('parent_folder ', parent_folder)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "0fb1802e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "parent_folder  /home/jin/gpt2_from_scratch/gpt2\n"
     ]
    }
   ],
   "source": [
    "from gpt_model import GPT2\n",
    "from gpt2_config.config import  GPT2Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "87684a99",
   "metadata": {},
   "outputs": [],
   "source": [
    "config = GPT2Config()\n",
    "model = GPT2(cfg=config)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aece9494",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "GPT2(\n",
       "  (tok_emb): Embedding(50257, 768)\n",
       "  (pos_emb): Embedding(1024, 768)\n",
       "  (drop_emb): Dropout(p=0.1, inplace=False)\n",
       "  (trf_blocks): Sequential(\n",
       "    (0): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (1): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (2): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (3): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (4): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (5): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (6): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (7): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (8): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (9): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (10): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "    (11): TransformerBlock(\n",
       "      (attn): MultiHeadAttention(\n",
       "        (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "        (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "        (dropout): Dropout(p=0.1, inplace=False)\n",
       "      )\n",
       "      (ff): FeedForward(\n",
       "        (layers): Sequential(\n",
       "          (0): Linear(in_features=768, out_features=3072, bias=True)\n",
       "          (1): GELU()\n",
       "          (2): Linear(in_features=3072, out_features=768, bias=True)\n",
       "        )\n",
       "      )\n",
       "      (norm1): LayerNorm()\n",
       "      (norm2): LayerNorm()\n",
       "      (drop_resid): Dropout(p=0.1, inplace=False)\n",
       "    )\n",
       "  )\n",
       "  (final_norm): LayerNorm()\n",
       "  (out_head): Linear(in_features=768, out_features=50257, bias=False)\n",
       ")"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d5e4ba46",
   "metadata": {},
   "source": [
    "<h3> GPT2 Model Architecture </h3>\n",
    "<table>\n",
    "  <thead>\n",
    "    <tr>\n",
    "      <th>Component</th>\n",
    "      <th>Parameters</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Token embedding</td>\n",
    "      <td>vocab_size=50257, embedding_dim=768</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Pos embedding</td>\n",
    "      <td>context_length=1024, embedding_dim=768</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Dropout</td>\n",
    "      <td>0.1</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>TransformerBlock</td>\n",
    "      <td>12 blocks</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>- MultiHeadAttention</td>\n",
    "      <td>(included in TransformerBlock)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>- FeedForward</td>\n",
    "      <td>(included in TransformerBlock)</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>- LayerNormalization</td>\n",
    "      <td>2 per block</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>FinalLayerNormalization</td>\n",
    "      <td>-</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Out_head</td>\n",
    "      <td>Linear(embedding_dim=768, vocab_size=50257)</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "b81849b2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([50257, 768])"
      ]
     },
     "execution_count": 6,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "model.out_head.weight.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "d71f4399",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import tiktoken"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "10d8d7b5",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d20d96ae",
   "metadata": {},
   "outputs": [],
   "source": [
    "text = \"hello, how are you?\"\n",
    "encoded = torch.tensor(tokenizer.encode(text)).unsqueeze(dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1dcd6c54",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "c7dec72b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits = model(encoded)\n",
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "50167c11",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[-0.1982,  0.7917, -0.9118,  ...,  0.1907,  0.4489, -0.1582],\n",
       "         [ 0.4839,  1.1872, -0.6211,  ..., -0.3756,  0.4446, -0.0110],\n",
       "         [ 0.6909, -0.5079, -0.7169,  ...,  0.9889, -1.4440,  0.4302],\n",
       "         [-0.0533, -0.6521,  0.5397,  ...,  0.8597, -0.9464,  0.4759],\n",
       "         [ 0.4242,  1.3716,  0.2615,  ...,  0.0305, -0.0355, -1.2658],\n",
       "         [-0.2974,  0.4777, -0.7035,  ..., -0.3165,  0.2918,  0.1201]]],\n",
       "       grad_fn=<UnsafeViewBackward0>)"
      ]
     },
     "execution_count": 12,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "59f97d28",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[1.3819e-05, 3.7187e-05, 6.7700e-06,  ..., 2.0388e-05,\n",
       "          2.6394e-05, 1.4383e-05],\n",
       "         [2.7233e-05, 5.5022e-05, 9.0198e-06,  ..., 1.1529e-05,\n",
       "          2.6184e-05, 1.6602e-05],\n",
       "         [3.3615e-05, 1.0137e-05, 8.2250e-06,  ..., 4.5282e-05,\n",
       "          3.9750e-06, 2.5900e-05],\n",
       "         [1.5969e-05, 8.7753e-06, 2.8897e-05,  ..., 3.9793e-05,\n",
       "          6.5378e-06, 2.7110e-05],\n",
       "         [2.5774e-05, 6.6476e-05, 2.1904e-05,  ..., 1.7386e-05,\n",
       "          1.6277e-05, 4.7560e-06],\n",
       "         [1.2457e-05, 2.7042e-05, 8.2994e-06,  ..., 1.2221e-05,\n",
       "          2.2454e-05, 1.8912e-05]]], grad_fn=<SoftmaxBackward0>)"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# convert logits into probabilities \n",
    "prob = torch.softmax(logits, dim=-1)\n",
    "prob"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "9b434cfd",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 50257])"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# get the last tokens \n",
    "next_token_logit = prob[:, -1, :] # means predict the token after last input token in my case was '?' \n",
    "next_token_logit.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "4d1863c1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[1.2457e-05, 2.7042e-05, 8.2994e-06,  ..., 1.2221e-05, 2.2454e-05,\n",
       "         1.8912e-05]], grad_fn=<SelectBackward0>)"
      ]
     },
     "execution_count": 29,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_logit"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "2574596d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([11657])"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "next_token_id = torch.argmax(next_token_logit, dim=-1)\n",
    "next_token_id"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "410d6b18",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "' tanks'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(next_token_id.tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "71e96168",
   "metadata": {},
   "outputs": [],
   "source": [
    "from generation.generate_text import generate_text"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "ba13a2ce",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx = generate_text(model, encoded, max_new_tokens=10, context_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "4730e7d4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[31373,    11,   703,   389,   345,    30, 33117, 30218, 17810, 24696,\n",
       "           1759, 35438,  8612, 47448, 12542,  5324]]),\n",
       " torch.Size([1, 16]))"
      ]
     },
     "execution_count": 19,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx, idx.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "aa01feca",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[31373,    11,   703,   389,   345,    30]])"
      ]
     },
     "execution_count": 20,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "encoded"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "e8071ee2",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, how are you? Clash cf horizon statisticplay Dmitgener618 throwsxx'"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(idx.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "7b6d7be7",
   "metadata": {},
   "outputs": [],
   "source": [
    "idx2 = generate_text(model, encoded, max_new_tokens=14, context_size=6)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "f590572b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'hello, how are you?fordicycle Shortly attributable Layer SUPER Wadoha inflammation Adapticycle Shortly genetically Aden'"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(idx2.squeeze().tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "6a5d96f6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 20])"
      ]
     },
     "execution_count": 24,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "idx2.shape"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "69cb07b0",
   "metadata": {},
   "source": [
    "<h3> Conclusion </h3>\n",
    "\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>Metric</th>\n",
    "      <th>Value</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Initial tokens</td>\n",
    "      <td>6</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Max new tokens</td>\n",
    "      <td>14</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Generated total tokens</td>\n",
    "      <td>20</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>\n",
    "<br>\n",
    "<table border=\"1\" class=\"dataframe\">\n",
    "  <thead>\n",
    "    <tr style=\"text-align: right;\">\n",
    "      <th>Reason for Random Output</th>\n",
    "      <th>Explanation</th>\n",
    "    </tr>\n",
    "  </thead>\n",
    "  <tbody>\n",
    "    <tr>\n",
    "      <td>Model is untrained</td>\n",
    "      <td>No learning has occurred</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Weighs are random</td>\n",
    "      <td>Parameters not optimized</td>\n",
    "    </tr>\n",
    "    <tr>\n",
    "      <td>Result</td>\n",
    "      <td>Model is basically guessing</td>\n",
    "    </tr>\n",
    "  </tbody>\n",
    "</table>"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "1d8c728f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([1, 6, 50257])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "072f2e5d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([6, 50257])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "logits_flat = logits.flatten(0,1)\n",
    "logits_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "71ef1342",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([1, 6]), torch.Size([6]))"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# targets \n",
    "target_text = \"i really like chocolate and you\"\n",
    "target = torch.tensor(tokenizer.encode(target_text)).unsqueeze(dim=0)\n",
    "target_flat = target.flatten(0, 1)\n",
    "target.shape, target_flat.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "a1f96275",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor(11.3242, grad_fn=<NllLossBackward0>)"
      ]
     },
     "execution_count": 28,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "torch.nn.functional.cross_entropy(logits_flat, target_flat)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5c9eec60",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
