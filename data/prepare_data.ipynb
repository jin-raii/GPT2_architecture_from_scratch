{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bdd9e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "95c65032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('flytech/python-codes-25k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bb66c73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 49626\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 35,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "e6e6054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': \"```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\",\n",
       " 'instruction': 'Help me set up my daily to-do list!',\n",
       " 'input': 'Setting up your daily to-do list...',\n",
       " 'text': \"Help me set up my daily to-do list! Setting up your daily to-do list... ```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\"}"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "ded0d4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset = data['train'].train_test_split(test_size=0.2, seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "2835aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "    # Alpeca style \n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately complets the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{data['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # Add input if it exists\n",
    "    if data.get(\"input\") and data[\"input\"].strip():\n",
    "        instruction_text += f\"\\n\\n### Input:\\n{data['input']}\"\n",
    "        \n",
    "    # Add the Response header and the actual output\n",
    "    # IMPORTANT: Add the EOS token at the very end so the model learns to STOP.\n",
    "    instruction_text += f\"\\n\\n### Response:\\n{data['output']}<|endoftext|>\"\n",
    "    return {\"text\": instruction_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "767a5dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately complets the request.\n",
      "\n",
      "### Instruction:\n",
      "Calculate how much time I spend on my phone per week!\n",
      "\n",
      "### Input:\n",
      "Calculating weekly phone usage...\n",
      "\n",
      "### Response:\n",
      "```python\n",
      "total_time = 0\n",
      "for i in range(1, 8):\n",
      "    time = float(input(f'Enter phone usage in hours for day {i}: '))\n",
      "    total_time += time\n",
      "print(f'You spend approximately {total_time} hours per week on your phone.')\n",
      "```<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(format_data(data['train'][2])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "93788b70",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Map: 100%|██████████| 49626/49626 [00:02<00:00, 18750.66 examples/s]\n"
     ]
    }
   ],
   "source": [
    "dataset = data.map(format_data)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "id": "d408159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately complets the request.\\n\\n### Instruction:\\nHelp me set up my daily to-do list!\\n\\n### Input:\\nSetting up your daily to-do list...\\n\\n### Response:\\n```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```<|endoftext|>\""
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 76,
   "id": "359a5dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 4963\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 76,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "train_data = dataset['train'].train_test_split(train_size=0.8, seed=42)\n",
    "test_data = dataset['train'].train_test_split(test_size=0.1)\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_data['train'],\n",
    "    \"val\": test_data['test'],\n",
    "    'test': train_data['test']\n",
    "})\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "9e7acb6f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input', 'text'],\n",
       "    num_rows: 5\n",
       "})"
      ]
     },
     "execution_count": 68,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# data['train'].select(range(5)) # select dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7860b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62aa1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset \n",
    "# shuffled_data = data['train'].shuffle(seed=42)\n",
    "\n",
    "# # calculate indicies \n",
    "# train_end = int(len(shuffled_data) * 0.8)\n",
    "# test_end = (train_end + int(len(shuffled_data) * 0.1))\n",
    "\n",
    "# train_data = shuffled_data.select(range(train_end)) # 0 to 39700 \n",
    "# test_data = shuffled_data.select(range(train_end, test_end)) # 39700 to 39700+4962\n",
    "# val_data = shuffled_data.select(range(test_end, len(shuffled_data))) # rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a729e232",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Dataset({\n",
       "     features: ['output', 'instruction', 'input', 'text'],\n",
       "     num_rows: 39700\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['output', 'instruction', 'input', 'text'],\n",
       "     num_rows: 4962\n",
       " }),\n",
       " Dataset({\n",
       "     features: ['output', 'instruction', 'input', 'text'],\n",
       "     num_rows: 4964\n",
       " }))"
      ]
     },
     "execution_count": 42,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "bd9edf07",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately complets the request.\n",
      "\n",
      "### Instruction:\n",
      "Generate a function in Python that takes two parameters and returns their product\n"
     ]
    }
   ],
   "source": [
    "print(format_data(train_data[2]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 77,
   "id": "0ad5f88e",
   "metadata": {},
   "outputs": [
    {
     "ename": "KeyError",
     "evalue": "\"Invalid key: 10. Please first select a split. For example: `my_dataset_dictionary['train'][10]`. Available splits: ['test', 'train']\"",
     "output_type": "error",
     "traceback": [
      "\u001b[31m---------------------------------------------------------------------------\u001b[39m",
      "\u001b[31mKeyError\u001b[39m                                  Traceback (most recent call last)",
      "\u001b[36mCell\u001b[39m\u001b[36m \u001b[39m\u001b[32mIn[77]\u001b[39m\u001b[32m, line 1\u001b[39m\n\u001b[32m----> \u001b[39m\u001b[32m1\u001b[39m \u001b[43mtrain_data\u001b[49m\u001b[43m[\u001b[49m\u001b[32;43m10\u001b[39;49m\u001b[43m]\u001b[49m\n",
      "\u001b[36mFile \u001b[39m\u001b[32m~/gpt2_from_scratch/.venv/lib/python3.11/site-packages/datasets/dataset_dict.py:92\u001b[39m, in \u001b[36mDatasetDict.__getitem__\u001b[39m\u001b[34m(self, k)\u001b[39m\n\u001b[32m     88\u001b[39m available_suggested_splits = [\n\u001b[32m     89\u001b[39m     split \u001b[38;5;28;01mfor\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m (Split.TRAIN, Split.TEST, Split.VALIDATION) \u001b[38;5;28;01mif\u001b[39;00m split \u001b[38;5;129;01min\u001b[39;00m \u001b[38;5;28mself\u001b[39m\n\u001b[32m     90\u001b[39m ]\n\u001b[32m     91\u001b[39m suggested_split = available_suggested_splits[\u001b[32m0\u001b[39m] \u001b[38;5;28;01mif\u001b[39;00m available_suggested_splits \u001b[38;5;28;01melse\u001b[39;00m \u001b[38;5;28mlist\u001b[39m(\u001b[38;5;28mself\u001b[39m)[\u001b[32m0\u001b[39m]\n\u001b[32m---> \u001b[39m\u001b[32m92\u001b[39m \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mKeyError\u001b[39;00m(\n\u001b[32m     93\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mInvalid key: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m. Please first select a split. For example: \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     94\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33m`my_dataset_dictionary[\u001b[39m\u001b[33m'\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msuggested_split\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m'\u001b[39m\u001b[33m][\u001b[39m\u001b[38;5;132;01m{\u001b[39;00mk\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m]`. \u001b[39m\u001b[33m\"\u001b[39m\n\u001b[32m     95\u001b[39m     \u001b[33mf\u001b[39m\u001b[33m\"\u001b[39m\u001b[33mAvailable splits: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28msorted\u001b[39m(\u001b[38;5;28mself\u001b[39m)\u001b[38;5;132;01m}\u001b[39;00m\u001b[33m\"\u001b[39m\n\u001b[32m     96\u001b[39m )\n",
      "\u001b[31mKeyError\u001b[39m: \"Invalid key: 10. Please first select a split. For example: `my_dataset_dictionary['train'][10]`. Available splits: ['test', 'train']\""
     ]
    }
   ],
   "source": [
    "train_data[10]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4c4b0170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42296\n"
     ]
    }
   ],
   "source": [
    "empty = 0 \n",
    "for c in data['train']:\n",
    "    if len(c['input']) <= 0: \n",
    "        empty += 1\n",
    "\n",
    "print(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1a363aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting the optimizer and learning rate scheduler...'"
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['input'][600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "id": "f37a4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import InstructDataset, collate_fn\n",
    "import tiktoken\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 83,
   "id": "43788a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "id": "156d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(\n",
    "    collate_fn, \n",
    "    device=device, \n",
    "    allowed_mask_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 84,
   "id": "eda40366",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = InstructDataset(split_dataset['train'], tokenizer)\n",
    "test_dataset = InstructDataset(split_dataset['test'], tokenizer)\n",
    "val_dataset = InstructDataset(split_dataset['val'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 86,
   "id": "a76851c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['output', 'instruction', 'input', 'text'],\n",
       "    num_rows: 39700\n",
       "})"
      ]
     },
     "execution_count": 86,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 88,
   "id": "12c87dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    drop_last=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 94,
   "id": "6eb18d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(functools.partial(<function collate_fn at 0x7a9a8d621940>, device='cpu', allowed_mask_length=1024),\n",
       " 7940)"
      ]
     },
     "execution_count": 94,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.collate_fn, len(train_loader) # 7940 * 5 = 39700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "id": "8bde2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    drop_last=True, \n",
    "    num_workers=0 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "c55fa6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    shuffle=True, \n",
    "    drop_last=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 98,
   "id": "16367e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1985, 992)"
      ]
     },
     "execution_count": 98,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 99,
   "id": "d593aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader..\n",
      "torch.Size([5, 200]) torch.Size([5, 200])\n"
     ]
    }
   ],
   "source": [
    "print('Train loader..')\n",
    "for inputs, targets in train_loader:\n",
    "    pass\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 100,
   "id": "5828909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vall loader..\n",
      "torch.Size([5, 234]) torch.Size([5, 234])\n"
     ]
    }
   ],
   "source": [
    "print('vall loader..')\n",
    "for inputs, targets in val_loader:\n",
    "    pass\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "id": "653a04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12653170"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens = 0 \n",
    "for inputs, targets in train_loader:\n",
    "    train_tokens += inputs.numel()\n",
    "\n",
    "train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "id": "01e657e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "215"
      ]
     },
     "execution_count": 102,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "id": "01fa32af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431,  1224,   912,   262,  2581,    13,   198,\n",
       "          198, 21017, 46486,    25,   198, 16594,   257,  2163,   287, 11361,\n",
       "          284, 15284,   262,   299,   400,  1988,   286,   262, 41566,   261,\n",
       "        44456,  8379,   767,   628, 18261,    25,   198, 15506,    63, 29412,\n",
       "          198,  4299, 12900,   261, 44456,     7,    77,  2599,   198,   220,\n",
       "          611,   299,  6624,   657,   393,   299,  6624,   352,    25,   198,\n",
       "          220,   220,   220,  1441,   299,   198,   220,  2073,    25,   198,\n",
       "          220,   220,   220,  1441, 12900,   261, 44456,     7,    77,   532,\n",
       "          352,     8,  1343, 12900,   261, 44456,     7,    77,   532,   362,\n",
       "            8,   198,   220,   220,   198, 20274,   796, 12900,   261, 44456,\n",
       "            7,    22,     8,   198,  4798,     7, 20274,     8,   198, 15506,\n",
       "           63, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256])"
      ]
     },
     "execution_count": 103,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 106,
   "id": "e3d205bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task. Write a response that appropriately complets the request.\\n\\n### Instruction:\\nWrite a function in Python to calculate the nth value of the Fibonacci sequence 7\\n\\n Response:\\n```python\\ndef fibonacci(n):\\n  if n == 0 or n == 1:\\n    return n\\n  else:\\n    return fibonacci(n - 1) + fibonacci(n - 2)\\n  \\nresult = fibonacci(7)\\nprint(result)\\n```<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
      ]
     },
     "execution_count": 106,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdf419cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
       "         2882,   326, 20431,  1224,   912,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198, 16594,   257,  2163,   287, 11361,   284,\n",
       "        15284,   262,   299,   400,  1988,   286,   262, 41566,   261, 44456,\n",
       "         8379,   767,   628, 18261,    25,   198, 15506,    63, 29412,   198,\n",
       "         4299, 12900,   261, 44456,     7,    77,  2599,   198,   220,   611,\n",
       "          299,  6624,   657,   393,   299,  6624,   352,    25,   198,   220,\n",
       "          220,   220,  1441,   299,   198,   220,  2073,    25,   198,   220,\n",
       "          220,   220,  1441, 12900,   261, 44456,     7,    77,   532,   352,\n",
       "            8,  1343, 12900,   261, 44456,     7,    77,   532,   362,     8,\n",
       "          198,   220,   220,   198, 20274,   796, 12900,   261, 44456,     7,\n",
       "           22,     8,   198,  4798,     7, 20274,     8,   198, 15506,    63,\n",
       "        50256,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100])"
      ]
     },
     "execution_count": 104,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we can see the first token is shifted by 1 and exccesive tokens is converted into mask -100 which will be ignored by cross_entropy_loss \n",
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fec5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057e5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
