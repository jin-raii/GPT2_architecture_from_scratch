{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "bdd9e1c2",
   "metadata": {},
   "outputs": [],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "95c65032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('flytech/python-codes-25k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "bb66c73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 49626\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 37,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "e6e6054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': \"```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\",\n",
       " 'instruction': 'Help me set up my daily to-do list!',\n",
       " 'input': 'Setting up your daily to-do list...',\n",
       " 'text': \"Help me set up my daily to-do list! Setting up your daily to-do list... ```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\"}"
      ]
     },
     "execution_count": 38,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "ded0d4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset = data['train'].train_test_split(test_size=0.2, seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "2835aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "    # Alpeca style \n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately complets the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{data['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # Add input if it exists\n",
    "    if data.get(\"input\") and data[\"input\"].strip():\n",
    "        instruction_text += f\"\\n\\n### Input:\\n{data['input']}\"\n",
    "        \n",
    "    # Add the Response header and the actual output\n",
    "    # IMPORTANT: Add the EOS token at the very end so the model learns to STOP.\n",
    "    instruction_text += f\"\\n\\n### Response:\\n{data['output']}<|endoftext|>\"\n",
    "    return {\"text\": instruction_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "767a5dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately complets the request.\n",
      "\n",
      "### Instruction:\n",
      "Calculate how much time I spend on my phone per week!\n",
      "\n",
      "### Input:\n",
      "Calculating weekly phone usage...\n",
      "\n",
      "### Response:\n",
      "```python\n",
      "total_time = 0\n",
      "for i in range(1, 8):\n",
      "    time = float(input(f'Enter phone usage in hours for day {i}: '))\n",
      "    total_time += time\n",
      "print(f'You spend approximately {total_time} hours per week on your phone.')\n",
      "```<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(format_data(data['train'][2])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "93788b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.map(format_data, remove_columns=['instruction', 'input', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "d408159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately complets the request.\\n\\n### Instruction:\\nHelp me set up my daily to-do list!\\n\\n### Input:\\nSetting up your daily to-do list...\\n\\n### Response:\\n```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```<|endoftext|>\""
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "359a5dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4963\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "train_data = dataset['train'].train_test_split(train_size=0.8, seed=42)\n",
    "test_data = dataset['train'].train_test_split(test_size=0.1)\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_data['train'],\n",
    "    \"val\": test_data['test'],\n",
    "    'test': train_data['test']\n",
    "})\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "id": "689192c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 39700/39700 [00:00<00:00, 168037.13 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4963/4963 [00:00<00:00, 163324.26 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9926/9926 [00:00<00:00, 178644.91 examples/s]\n"
     ]
    }
   ],
   "source": [
    "split_dataset.save_to_disk('../final_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "9e7acb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['train'].select(range(5)) # select dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7860b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "62aa1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset \n",
    "# shuffled_data = data['train'].shuffle(seed=42)\n",
    "\n",
    "# # calculate indicies \n",
    "# train_end = int(len(shuffled_data) * 0.8)\n",
    "# test_end = (train_end + int(len(shuffled_data) * 0.1))\n",
    "\n",
    "# train_data = shuffled_data.select(range(train_end)) # 0 to 39700 \n",
    "# test_data = shuffled_data.select(range(train_end, test_end)) # 39700 to 39700+4962\n",
    "# val_data = shuffled_data.select(range(test_end, len(shuffled_data))) # rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "a729e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "4c4b0170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42296\n"
     ]
    }
   ],
   "source": [
    "empty = 0 \n",
    "for c in data['train']:\n",
    "    if len(c['input']) <= 0: \n",
    "        empty += 1\n",
    "\n",
    "print(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "1a363aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting the optimizer and learning rate scheduler...'"
      ]
     },
     "execution_count": 49,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['input'][600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "f37a4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import InstructDataset, collate_fn\n",
    "import tiktoken\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "43788a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "156d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(\n",
    "    collate_fn, \n",
    "    device=device, \n",
    "    allowed_mask_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "eda40366",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = InstructDataset(split_dataset['train'], tokenizer)\n",
    "test_dataset = InstructDataset(split_dataset['test'], tokenizer)\n",
    "val_dataset = InstructDataset(split_dataset['val'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "a76851c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 39700\n",
       "})"
      ]
     },
     "execution_count": 54,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "12c87dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 5\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    drop_last=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "id": "6eb18d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(functools.partial(<function collate_fn at 0x7a5b3c5fd6c0>, device='cpu', allowed_mask_length=1024),\n",
       " 7940)"
      ]
     },
     "execution_count": 56,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.collate_fn, len(train_loader) # 7940 * 5 = 39700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "id": "8bde2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    drop_last=True, \n",
    "    num_workers=0 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "id": "c55fa6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    shuffle=True, \n",
    "    drop_last=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "id": "906f5861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 59,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "id": "16367e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1985, 992)"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "id": "d593aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader..\n",
      "torch.Size([5, 216]) torch.Size([5, 216])\n"
     ]
    }
   ],
   "source": [
    "print('Train loader..')\n",
    "for inputs, targets in train_loader:\n",
    "    pass\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "id": "5828909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vall loader..\n",
      "torch.Size([5, 319]) torch.Size([5, 319])\n"
     ]
    }
   ],
   "source": [
    "print('vall loader..')\n",
    "for inputs, targets in val_loader:\n",
    "    pass\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "id": "653a04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "12770460"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens = 0 \n",
    "for inputs, targets in train_loader:\n",
    "    train_tokens += inputs.numel()\n",
    "\n",
    "train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "id": "01e657e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "255"
      ]
     },
     "execution_count": 64,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "id": "01fa32af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431,  1224,   912,   262,  2581,    13,   198,\n",
       "          198, 21017, 46486,    25,   198, 16447,   257,  2163,   287, 11361,\n",
       "          326,  2753,   734, 13042,   290, 21001,   262,  3435,   286,  1123,\n",
       "         4731,  5291,   262,  1502,   286,   262,  3435, 22944,   198,  5657,\n",
       "          198,   198, 21017, 18261,    25,   198, 15506,    63, 29412,   198,\n",
       "         4299, 12082,     7,    82,    16,    11,   264,    17,  2599,   198,\n",
       "          220,   220,   220,  1255,   796, 13538,   220,   198,   220,   220,\n",
       "          220,   329,  1312,   287,  2837,     7,  9806,     7, 11925,     7,\n",
       "           82,    16,   828, 18896,     7,    82,    17,  4008,  2599,   198,\n",
       "          220,   220,   220,   220,   220,   220,   220,   611,  1312,  1279,\n",
       "        18896,     7,    82,    16,  2599,   198,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,  1255, 15853,   264,\n",
       "           16,    58,    72,    60,   198,   220,   220,   220,   220,   220,\n",
       "          220,   220,   611,  1312,  1279, 18896,     7,    82,    17,  2599,\n",
       "          198,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,  1255, 15853,   264,    17,    58,    72,    60,   198,\n",
       "          220,   220,   220,  1441,  1255,   198, 15506,    63, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256, 50256,\n",
       "        50256, 50256, 50256, 50256, 50256])"
      ]
     },
     "execution_count": 65,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "id": "e3d205bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Below is an instruction that describes a task. Write a response that appropriately complets the request.\\n\\n### Instruction:\\nCreate a function in Python that takes two strings and combines the characters of each string keeping the order of the characters foo\\nbar\\n\\n### Response:\\n```python\\ndef combine(s1, s2):\\n    result = \"\" \\n    for i in range(max(len(s1), len(s2))):\\n        if i < len(s1):\\n            result += s1[i]\\n        if i < len(s2):\\n            result += s2[i]\\n    return result\\n```<|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|><|endoftext|>'"
      ]
     },
     "execution_count": 66,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "id": "cdf419cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
       "         2882,   326, 20431,  1224,   912,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198, 16447,   257,  2163,   287, 11361,   326,\n",
       "         2753,   734, 13042,   290, 21001,   262,  3435,   286,  1123,  4731,\n",
       "         5291,   262,  1502,   286,   262,  3435, 22944,   198,  5657,   198,\n",
       "          198, 21017, 18261,    25,   198, 15506,    63, 29412,   198,  4299,\n",
       "        12082,     7,    82,    16,    11,   264,    17,  2599,   198,   220,\n",
       "          220,   220,  1255,   796, 13538,   220,   198,   220,   220,   220,\n",
       "          329,  1312,   287,  2837,     7,  9806,     7, 11925,     7,    82,\n",
       "           16,   828, 18896,     7,    82,    17,  4008,  2599,   198,   220,\n",
       "          220,   220,   220,   220,   220,   220,   611,  1312,  1279, 18896,\n",
       "            7,    82,    16,  2599,   198,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,  1255, 15853,   264,    16,\n",
       "           58,    72,    60,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,   611,  1312,  1279, 18896,     7,    82,    17,  2599,   198,\n",
       "          220,   220,   220,   220,   220,   220,   220,   220,   220,   220,\n",
       "          220,  1255, 15853,   264,    17,    58,    72,    60,   198,   220,\n",
       "          220,   220,  1441,  1255,   198, 15506,    63, 50256,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,  -100,\n",
       "         -100,  -100,  -100,  -100,  -100])"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we can see the first token is shifted by 1 and exccesive tokens is converted into mask -100 which will be ignored by cross_entropy_loss \n",
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fec5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057e5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
