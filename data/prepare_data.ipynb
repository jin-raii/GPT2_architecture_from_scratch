{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "bdd9e1c2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/home/jin/gpt2_from_scratch/.venv/lib/python3.11/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "from datasets import load_dataset\n",
    "from torch.utils.data import DataLoader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "95c65032",
   "metadata": {},
   "outputs": [],
   "source": [
    "data = load_dataset('flytech/python-codes-25k')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "bb66c73f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 49626\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "e6e6054f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'output': \"```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\",\n",
       " 'instruction': 'Help me set up my daily to-do list!',\n",
       " 'input': 'Setting up your daily to-do list...',\n",
       " 'text': \"Help me set up my daily to-do list! Setting up your daily to-do list... ```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```\"}"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train'][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "ded0d4a7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['output', 'instruction', 'input', 'text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "split_dataset = data['train'].train_test_split(test_size=0.2, seed=42)\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "2835aaed",
   "metadata": {},
   "outputs": [],
   "source": [
    "def format_data(data):\n",
    "    # Alpeca style \n",
    "    instruction_text = (\n",
    "        f\"Below is an instruction that describes a task. \"\n",
    "        f\"Write a response that appropriately complets the request.\"\n",
    "        f\"\\n\\n### Instruction:\\n{data['instruction']}\"\n",
    "    )\n",
    "\n",
    "    # Add input if it exists\n",
    "    if data.get(\"input\") and data[\"input\"].strip():\n",
    "        instruction_text += f\"\\n\\n### Input:\\n{data['input']}\"\n",
    "        \n",
    "    # Add the Response header and the actual output\n",
    "    # IMPORTANT: Add the EOS token at the very end so the model learns to STOP.\n",
    "    instruction_text += f\"\\n\\n### Response:\\n{data['output']}<|endoftext|>\"\n",
    "    return {\"text\": instruction_text}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "767a5dc7",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Below is an instruction that describes a task. Write a response that appropriately complets the request.\n",
      "\n",
      "### Instruction:\n",
      "Calculate how much time I spend on my phone per week!\n",
      "\n",
      "### Input:\n",
      "Calculating weekly phone usage...\n",
      "\n",
      "### Response:\n",
      "```python\n",
      "total_time = 0\n",
      "for i in range(1, 8):\n",
      "    time = float(input(f'Enter phone usage in hours for day {i}: '))\n",
      "    total_time += time\n",
      "print(f'You spend approximately {total_time} hours per week on your phone.')\n",
      "```<|endoftext|>\n"
     ]
    }
   ],
   "source": [
    "print(format_data(data['train'][2])['text'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "93788b70",
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = data.map(format_data, remove_columns=['instruction', 'input', 'output'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "d408159c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately complets the request.\\n\\n### Instruction:\\nHelp me set up my daily to-do list!\\n\\n### Input:\\nSetting up your daily to-do list...\\n\\n### Response:\\n```python\\ntasks = []\\nwhile True:\\n    task = input('Enter a task or type 'done' to finish: ')\\n    if task == 'done': break\\n    tasks.append(task)\\nprint(f'Your to-do list for today: {tasks}')\\n```<|endoftext|>\""
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "dataset['train'][0]['text']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "359a5dbf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    val: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 4963\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from datasets import DatasetDict\n",
    "\n",
    "train_data = dataset['train'].train_test_split(train_size=0.8, seed=42)\n",
    "test_data = dataset['train'].train_test_split(test_size=0.1)\n",
    "split_dataset = DatasetDict({\n",
    "    \"train\": train_data['train'],\n",
    "    \"val\": test_data['test'],\n",
    "    'test': train_data['test']\n",
    "})\n",
    "split_dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "689192c5",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Saving the dataset (1/1 shards): 100%|██████████| 39700/39700 [00:00<00:00, 169897.03 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 4963/4963 [00:00<00:00, 183854.12 examples/s]\n",
      "Saving the dataset (1/1 shards): 100%|██████████| 9926/9926 [00:00<00:00, 190723.55 examples/s]\n"
     ]
    }
   ],
   "source": [
    "split_dataset.save_to_disk('../final_dataset')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "id": "9e7acb6f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# data['train'].select(range(5)) # select dataset "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "58f7860b",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "62aa1a75",
   "metadata": {},
   "outputs": [],
   "source": [
    "# shuffle dataset \n",
    "# shuffled_data = data['train'].shuffle(seed=42)\n",
    "\n",
    "# # calculate indicies \n",
    "# train_end = int(len(shuffled_data) * 0.8)\n",
    "# test_end = (train_end + int(len(shuffled_data) * 0.1))\n",
    "\n",
    "# train_data = shuffled_data.select(range(train_end)) # 0 to 39700 \n",
    "# test_data = shuffled_data.select(range(train_end, test_end)) # 39700 to 39700+4962\n",
    "# val_data = shuffled_data.select(range(test_end, len(shuffled_data))) # rest "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "a729e232",
   "metadata": {},
   "outputs": [],
   "source": [
    "# train_data, test_data, val_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "4c4b0170",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "42296\n"
     ]
    }
   ],
   "source": [
    "empty = 0 \n",
    "for c in data['train']:\n",
    "    if len(c['input']) <= 0: \n",
    "        empty += 1\n",
    "\n",
    "print(empty)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "1a363aab",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'Setting the optimizer and learning rate scheduler...'"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "data['train']['input'][600]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "f37a4d9f",
   "metadata": {},
   "outputs": [],
   "source": [
    "from dataset import InstructDataset, collate_fn\n",
    "import tiktoken\n",
    "from functools import partial"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "43788a08",
   "metadata": {},
   "outputs": [],
   "source": [
    "tokenizer = tiktoken.get_encoding('gpt2')\n",
    "device='cpu'"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "156d6db8",
   "metadata": {},
   "outputs": [],
   "source": [
    "customized_collate_fn = partial(\n",
    "    collate_fn, \n",
    "    device=device, \n",
    "    allowed_mask_length=1024\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "id": "eda40366",
   "metadata": {},
   "outputs": [],
   "source": [
    "train_dataset = InstructDataset(split_dataset['train'], tokenizer)\n",
    "test_dataset = InstructDataset(split_dataset['test'], tokenizer)\n",
    "val_dataset = InstructDataset(split_dataset['val'], tokenizer)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "a76851c4",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Dataset({\n",
       "    features: ['text'],\n",
       "    num_rows: 39700\n",
       "})"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_dataset.data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "12c87dc7",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch_size = 8\n",
    "\n",
    "train_loader = DataLoader(\n",
    "    train_dataset, \n",
    "    batch_size=batch_size,\n",
    "    shuffle=True, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    drop_last=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "6eb18d7a",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(functools.partial(<function collate_fn at 0x7a2a090e36a0>, device='cpu', allowed_mask_length=1024),\n",
       " 4962)"
      ]
     },
     "execution_count": 36,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_loader.collate_fn, len(train_loader) # 7940 * 5 = 39700"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "8bde2e67",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "test_loader = DataLoader(\n",
    "    dataset=test_dataset, \n",
    "    batch_size=batch_size, \n",
    "    shuffle=True, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    drop_last=True, \n",
    "    num_workers=0 \n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "c55fa6b7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "val_loader = DataLoader(\n",
    "    dataset=val_dataset, \n",
    "    batch_size=batch_size, \n",
    "    collate_fn=customized_collate_fn, \n",
    "    shuffle=True, \n",
    "    drop_last=True, \n",
    "    num_workers=0\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "906f5861",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "DatasetDict({\n",
       "    train: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 39700\n",
       "    })\n",
       "    test: Dataset({\n",
       "        features: ['text'],\n",
       "        num_rows: 9926\n",
       "    })\n",
       "})"
      ]
     },
     "execution_count": 39,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "16367e73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(1240, 620)"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(test_loader), len(val_loader)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "d593aea5",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Train loader..\n",
      "torch.Size([8, 157]) torch.Size([8, 157])\n"
     ]
    }
   ],
   "source": [
    "print('Train loader..')\n",
    "for inputs, targets in train_loader:\n",
    "    pass\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "5828909b",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "vall loader..\n",
      "torch.Size([8, 241]) torch.Size([8, 241])\n"
     ]
    }
   ],
   "source": [
    "print('vall loader..')\n",
    "for inputs, targets in val_loader:\n",
    "    pass\n",
    "print(inputs.shape, targets.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "653a04f8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "14458752"
      ]
     },
     "execution_count": 43,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_tokens = 0 \n",
    "for inputs, targets in train_loader:\n",
    "    train_tokens += inputs.numel()\n",
    "\n",
    "train_tokens"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "01e657e0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "506"
      ]
     },
     "execution_count": 44,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "len(inputs[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "01fa32af",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([21106,   318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,\n",
       "          257,  2882,   326, 20431,  1224,   912,   262,  2581,    13,   198,\n",
       "          198, 21017, 46486,    25,   198, 16447,   257,  2163,   326,  6673,\n",
       "          262,  1573,   705,  1069,  5666,     6,   355,   262,   938,  5002,\n",
       "          287,   597,  1813,  1351,    13,   383,  1351,   481,  2291,  5701,\n",
       "           12,  5363,  2456,    13,   383,  2163,   815,   664,  1834,  2280,\n",
       "          751,   262,  1573,   705,  1069,  5666,     6,  1566,   262,  1351,\n",
       "         4129, 21767,   838,    13,  4418,    11,   878,  4375,   262,  5002,\n",
       "           11,   262,  2163,   815,  2198,   611,   705,  1069,  5666,     6,\n",
       "         1541,  7160,   287,   262,  1351,    13,  1002,   705,  1069,  5666,\n",
       "            6,  1541,  7160,    11,   262,  2163,   815,  2427,   751,   262,\n",
       "         1573,   705, 11274,  4458, 27814,   262,  2457,  8341,   618,   262,\n",
       "         5128,  1351,  1595,   470,   423,   705,  1069,  5666,     6,   290,\n",
       "          857,   423,   705,  1069,  5666,  4458,   198,   198, 20556,  1351,\n",
       "          532, 37250, 35634,  2189,  3256,   705,  2143,  1525,  3256,   705,\n",
       "           71,  8337, 20520,   198,   198, 21017, 18261,    25,   198,  4342,\n",
       "          318,   262, 11361,  2438,    25,   628,   198,  4299,   751,    62,\n",
       "         4775,     7,    75,   301,  2599,   198,   220,   220,   220,   611,\n",
       "        18896,     7,    75,   301,     8,    27,   940,    25,   198,   220,\n",
       "          220,   220,   220,   220,   220,   220,   611,   705,  1069,  5666,\n",
       "            6,   287,   300,   301,    25,   198,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   220,   300,   301,    13,\n",
       "        33295, 10786, 11274, 11537,   198,   220,   220,   220,   220,   220,\n",
       "          220,   220,  2073,    25,   198,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   300,   301,    13, 33295,\n",
       "        10786,  1069,  5666, 11537,   198,   220,   220,   220,   220,   220,\n",
       "          220,   220,  1441,   751,    62,  4775,     7,    75,   301,     8,\n",
       "          198,   220,   220,   220,  2073,    25,   198,   220,   220,   220,\n",
       "          220,   220,   220,   220,  1441,   300,   301,   198,   198,     2,\n",
       "        13745,  1351,  1231,   705,  1069,  5666,     6,   198,    75,   301,\n",
       "           16,   796, 37250, 35634,  2189,  3256,   705,  2143,  1525,  3256,\n",
       "          705,    71,  8337, 20520,   198,  4798,     7,  2860,    62,  4775,\n",
       "            7,    75,   301,    16,  4008,   198,   198,     2, 13745,  1351,\n",
       "          351,   705,  1069,  5666,     6,   198,    75,   301,    17,   796,\n",
       "        37250, 35634,  2189,  3256,   705,  2143,  1525,  3256,   705,    71,\n",
       "         8337,  3256,   705,  1069,  5666, 20520,   198,  4798,     7,  2860,\n",
       "           62,  4775,     7,    75,   301,    17,  4008,   628,   198,  1532,\n",
       "          262,  2656,  1351,   318, 37250, 35634,  2189,  3256,   705,  2143,\n",
       "         1525,  3256,   705,    71,  8337,     6,  4357,   262,  5072,   286,\n",
       "          262,  1430,   481,   307,    25,   198,   198, 17816, 35634,  2189,\n",
       "         3256,   705,  2143,  1525,  3256,   705,    71,  8337,  3256,   705,\n",
       "         1069,  5666,  3256,   705,  1069,  5666,  3256,   705,  1069,  5666,\n",
       "         3256,   705,  1069,  5666,  3256,   705,  1069,  5666,  3256,   705,\n",
       "         1069,  5666,  3256,   705,  1069,  5666, 20520,   198,   198,  1532,\n",
       "          262,  2656,  1351,   318, 37250, 35634,  2189,  3256,   705,  2143,\n",
       "         1525,  3256,   705,    71,  8337,  3256,   705,  1069,  5666,     6,\n",
       "         4357,   262,  5072,   286,   262,  1430,   481,   307,    25,   198,\n",
       "          198, 17816, 35634,  2189,  3256,   705,  2143,  1525,  3256,   705,\n",
       "           71,  8337,  3256,   705,  1069,  5666,  3256,   705, 11274,  3256,\n",
       "          705, 11274,  3256,   705, 11274,  3256,   705, 11274,  3256,   705,\n",
       "        11274,  3256,   705, 11274, 20520, 50256])"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "inputs[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "e3d205bc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Below is an instruction that describes a task. Write a response that appropriately complets the request.\\n\\n### Instruction:\\nCreate a function that adds the word 'excellent' as the last element in any given list. The list will include sports-related words. The function should recursively add the word 'excellent' until the list length equals 10. Also, before adding the element, the function should check if 'excellent' already exists in the list. If 'excellent' already exists, the function should instead add the word 'good'. Compare the final lists when the input list doesn't have 'excellent' and does have 'excellent'.\\n\\nOriginal list - ['soccer', 'rugby', 'hockey']\\n\\n### Response:\\nHere is the Python code:\\n\\n\\ndef add_word(lst):\\n    if len(lst)<10:\\n        if 'excellent' in lst:\\n            lst.append('good')\\n        else:\\n            lst.append('excellent')\\n        return add_word(lst)\\n    else:\\n        return lst\\n\\n# Original list without 'excellent'\\nlst1 = ['soccer', 'rugby', 'hockey']\\nprint(add_word(lst1))\\n\\n# Original list with 'excellent'\\nlst2 = ['soccer', 'rugby', 'hockey', 'excellent']\\nprint(add_word(lst2))\\n\\n\\nIf the original list is ['soccer', 'rugby', 'hockey'], the output of the program will be:\\n\\n['soccer', 'rugby', 'hockey', 'excellent', 'excellent', 'excellent', 'excellent', 'excellent', 'excellent', 'excellent']\\n\\nIf the original list is ['soccer', 'rugby', 'hockey', 'excellent'], the output of the program will be:\\n\\n['soccer', 'rugby', 'hockey', 'excellent', 'good', 'good', 'good', 'good', 'good', 'good']<|endoftext|>\""
      ]
     },
     "execution_count": 46,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "tokenizer.decode(inputs[0].tolist())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "cdf419cc",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([  318,   281, 12064,   326,  8477,   257,  4876,    13, 19430,   257,\n",
       "         2882,   326, 20431,  1224,   912,   262,  2581,    13,   198,   198,\n",
       "        21017, 46486,    25,   198, 16447,   257,  2163,   326,  6673,   262,\n",
       "         1573,   705,  1069,  5666,     6,   355,   262,   938,  5002,   287,\n",
       "          597,  1813,  1351,    13,   383,  1351,   481,  2291,  5701,    12,\n",
       "         5363,  2456,    13,   383,  2163,   815,   664,  1834,  2280,   751,\n",
       "          262,  1573,   705,  1069,  5666,     6,  1566,   262,  1351,  4129,\n",
       "        21767,   838,    13,  4418,    11,   878,  4375,   262,  5002,    11,\n",
       "          262,  2163,   815,  2198,   611,   705,  1069,  5666,     6,  1541,\n",
       "         7160,   287,   262,  1351,    13,  1002,   705,  1069,  5666,     6,\n",
       "         1541,  7160,    11,   262,  2163,   815,  2427,   751,   262,  1573,\n",
       "          705, 11274,  4458, 27814,   262,  2457,  8341,   618,   262,  5128,\n",
       "         1351,  1595,   470,   423,   705,  1069,  5666,     6,   290,   857,\n",
       "          423,   705,  1069,  5666,  4458,   198,   198, 20556,  1351,   532,\n",
       "        37250, 35634,  2189,  3256,   705,  2143,  1525,  3256,   705,    71,\n",
       "         8337, 20520,   198,   198, 21017, 18261,    25,   198,  4342,   318,\n",
       "          262, 11361,  2438,    25,   628,   198,  4299,   751,    62,  4775,\n",
       "            7,    75,   301,  2599,   198,   220,   220,   220,   611, 18896,\n",
       "            7,    75,   301,     8,    27,   940,    25,   198,   220,   220,\n",
       "          220,   220,   220,   220,   220,   611,   705,  1069,  5666,     6,\n",
       "          287,   300,   301,    25,   198,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   220,   300,   301,    13, 33295,\n",
       "        10786, 11274, 11537,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,  2073,    25,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,   220,   220,   220,   220,   300,   301,    13, 33295, 10786,\n",
       "         1069,  5666, 11537,   198,   220,   220,   220,   220,   220,   220,\n",
       "          220,  1441,   751,    62,  4775,     7,    75,   301,     8,   198,\n",
       "          220,   220,   220,  2073,    25,   198,   220,   220,   220,   220,\n",
       "          220,   220,   220,  1441,   300,   301,   198,   198,     2, 13745,\n",
       "         1351,  1231,   705,  1069,  5666,     6,   198,    75,   301,    16,\n",
       "          796, 37250, 35634,  2189,  3256,   705,  2143,  1525,  3256,   705,\n",
       "           71,  8337, 20520,   198,  4798,     7,  2860,    62,  4775,     7,\n",
       "           75,   301,    16,  4008,   198,   198,     2, 13745,  1351,   351,\n",
       "          705,  1069,  5666,     6,   198,    75,   301,    17,   796, 37250,\n",
       "        35634,  2189,  3256,   705,  2143,  1525,  3256,   705,    71,  8337,\n",
       "         3256,   705,  1069,  5666, 20520,   198,  4798,     7,  2860,    62,\n",
       "         4775,     7,    75,   301,    17,  4008,   628,   198,  1532,   262,\n",
       "         2656,  1351,   318, 37250, 35634,  2189,  3256,   705,  2143,  1525,\n",
       "         3256,   705,    71,  8337,     6,  4357,   262,  5072,   286,   262,\n",
       "         1430,   481,   307,    25,   198,   198, 17816, 35634,  2189,  3256,\n",
       "          705,  2143,  1525,  3256,   705,    71,  8337,  3256,   705,  1069,\n",
       "         5666,  3256,   705,  1069,  5666,  3256,   705,  1069,  5666,  3256,\n",
       "          705,  1069,  5666,  3256,   705,  1069,  5666,  3256,   705,  1069,\n",
       "         5666,  3256,   705,  1069,  5666, 20520,   198,   198,  1532,   262,\n",
       "         2656,  1351,   318, 37250, 35634,  2189,  3256,   705,  2143,  1525,\n",
       "         3256,   705,    71,  8337,  3256,   705,  1069,  5666,     6,  4357,\n",
       "          262,  5072,   286,   262,  1430,   481,   307,    25,   198,   198,\n",
       "        17816, 35634,  2189,  3256,   705,  2143,  1525,  3256,   705,    71,\n",
       "         8337,  3256,   705,  1069,  5666,  3256,   705, 11274,  3256,   705,\n",
       "        11274,  3256,   705, 11274,  3256,   705, 11274,  3256,   705, 11274,\n",
       "         3256,   705, 11274, 20520, 50256,  -100])"
      ]
     },
     "execution_count": 47,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# as we can see the first token is shifted by 1 and exccesive tokens is converted into mask -100 which will be ignored by cross_entropy_loss \n",
    "targets[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e2fec5e8",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e057e5b9",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
