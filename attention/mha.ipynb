{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "4f427c2a",
   "metadata": {},
   "outputs": [],
   "source": [
    "import sys \n",
    "from pathlib import Path\n",
    "import os"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "bdbc7d73",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "PosixPath('/home/jin/gpt2_from_scratch')"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "parent_dir = Path(os.getcwd()).resolve().parent\n",
    "parent_dir"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "4ebe5a1c",
   "metadata": {},
   "outputs": [],
   "source": [
    "sys.path.insert(0, str(parent_dir))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "dce55de9",
   "metadata": {},
   "outputs": [],
   "source": [
    "from gpt2.config import GPT2Config\n",
    "from multihead_attn import MultiHeadAttention"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c03961c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1024"
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "config = GPT2Config()\n",
    "\n",
    "config.context_length"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "154298d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhattn = MultiHeadAttention(d_in=config.emb_dim, d_out=config.emb_dim, context_length=config.context_length, dropout=config.drop_rate, num_heads=config.n_heads)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "9633ddd8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "MultiHeadAttention(\n",
       "  (W_query): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (W_key): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (W_value): Linear(in_features=768, out_features=768, bias=False)\n",
       "  (out_proj): Linear(in_features=768, out_features=768, bias=True)\n",
       "  (dropout): Dropout(p=0.1, inplace=False)\n",
       ")"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "mhattn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "ff0a9036",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch \n",
    "inputs = torch.tensor(\n",
    "  [[0.43, 0.15, 0.89], # Your     (x^1)\n",
    "   [0.55, 0.87, 0.66], # journey  (x^2)\n",
    "   [0.57, 0.85, 0.64], # starts   (x^3)\n",
    "   [0.22, 0.58, 0.33], # with     (x^4)\n",
    "   [0.77, 0.25, 0.10], # one      (x^5)\n",
    "   [0.05, 0.80, 0.55]] # step     (x^6)\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "dfe40525",
   "metadata": {},
   "outputs": [],
   "source": [
    "batch = torch.stack((inputs, inputs), dim=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "3283a3ee",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 3])"
      ]
     },
     "execution_count": 25,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "4e8078f5",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[0.4300, 0.1500, 0.8900],\n",
       "         [0.5500, 0.8700, 0.6600],\n",
       "         [0.5700, 0.8500, 0.6400],\n",
       "         [0.2200, 0.5800, 0.3300],\n",
       "         [0.7700, 0.2500, 0.1000],\n",
       "         [0.0500, 0.8000, 0.5500]],\n",
       "\n",
       "        [[0.4300, 0.1500, 0.8900],\n",
       "         [0.5500, 0.8700, 0.6600],\n",
       "         [0.5700, 0.8500, 0.6400],\n",
       "         [0.2200, 0.5800, 0.3300],\n",
       "         [0.7700, 0.2500, 0.1000],\n",
       "         [0.0500, 0.8000, 0.5500]]])"
      ]
     },
     "execution_count": 26,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "batch"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fd6ebbb2",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhattn2 = MultiHeadAttention(d_in=3, d_out=2, context_length=20, dropout=0.1, num_heads=2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "bd16707d",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[[ 0.7295, -0.1665],\n",
       "         [ 0.7407, -0.1827],\n",
       "         [ 0.7428, -0.1680],\n",
       "         [ 0.7582, -0.1702],\n",
       "         [ 0.7507, -0.1693],\n",
       "         [ 0.7148, -0.1878]],\n",
       "\n",
       "        [[ 0.7237, -0.1886],\n",
       "         [ 0.7588, -0.1698],\n",
       "         [ 0.7588, -0.1698],\n",
       "         [ 0.6875, -0.2204],\n",
       "         [ 0.7573, -0.1709],\n",
       "         [ 0.7583, -0.1701]]], grad_fn=<ViewBackward0>)"
      ]
     },
     "execution_count": 33,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec = mhattn2(batch)\n",
    "context_vec"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "29421150",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "torch.Size([2, 6, 2])"
      ]
     },
     "execution_count": 34,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "9a0b53e4",
   "metadata": {},
   "outputs": [],
   "source": [
    "mhattn3 = MultiHeadAttention(d_in=3, d_out=6, context_length=20, dropout=0.1, num_heads=3)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "d3d4a77c",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[[ 0.4865,  0.4277, -0.3363, -0.3032, -0.1415, -0.3766],\n",
       "          [ 0.4774,  0.4242, -0.3398, -0.3049, -0.1403, -0.3755],\n",
       "          [ 0.4672,  0.4218, -0.3516, -0.2845, -0.1429, -0.3842],\n",
       "          [ 0.4104,  0.3856, -0.3526, -0.2822, -0.1214, -0.3363],\n",
       "          [ 0.4829,  0.4285, -0.3373, -0.3016, -0.1437, -0.3777],\n",
       "          [ 0.4737,  0.4240, -0.3395, -0.3047, -0.1415, -0.3741]],\n",
       " \n",
       "         [[ 0.4865,  0.4277, -0.3363, -0.3032, -0.1415, -0.3766],\n",
       "          [ 0.5035,  0.4312, -0.3267, -0.2956, -0.1273, -0.3662],\n",
       "          [ 0.4834,  0.4270, -0.3383, -0.3018, -0.1423, -0.3775],\n",
       "          [ 0.4796,  0.4272, -0.3378, -0.3017, -0.1438, -0.3762],\n",
       "          [ 0.4845,  0.4115, -0.3396, -0.2743, -0.1114, -0.3593],\n",
       "          [ 0.5000,  0.4309, -0.3262, -0.2954, -0.1280, -0.3643]]],\n",
       "        grad_fn=<ViewBackward0>),\n",
       " torch.Size([2, 6, 6]))"
      ]
     },
     "execution_count": 40,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "context_vec3 = mhattn3(batch)\n",
    "context_vec3, context_vec3.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2ab54b3b",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": ".venv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
